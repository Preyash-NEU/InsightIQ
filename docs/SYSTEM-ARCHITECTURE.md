# InsightIQ - System Architecture & Design
**Version:** 1.0  
**Last Updated:** November 30, 2024  
**Environment:** Windows 11 + Docker + VS Code

---

## ğŸ“‹ Table of Contents
1. [Technology Stack](#technology-stack)
2. [System Architecture](#system-architecture)
3. [Database Schema](#database-schema)
4. [API Design](#api-design)
5. [Authentication & Security](#authentication--security)
6. [Data Flow](#data-flow)
7. [File Storage Strategy](#file-storage-strategy)
8. [External Integrations](#external-integrations)
9. [Deployment Architecture](#deployment-architecture)

---

## ğŸ› ï¸ Technology Stack

### Backend
```yaml
Language: Python 3.11+
Framework: FastAPI 0.104+
ORM: SQLAlchemy 2.0+
Database: PostgreSQL 15+
Cache: Redis 7+
Task Queue: Celery (optional for async tasks)
AI/ML: OpenAI API (GPT-4 for natural language queries)
Data Processing: Pandas, NumPy
```

### Frontend
```yaml
Framework: React 18+
Language: TypeScript 5+
Build Tool: Vite 5+
State Management: React Context API / Zustand
Styling: Tailwind CSS 3+
Icons: Lucide React
Charts: Recharts / Chart.js
HTTP Client: Axios
```

### DevOps & Infrastructure
```yaml
Containerization: Docker + Docker Compose
Reverse Proxy: Nginx (production)
Process Manager: PM2 / Gunicorn
Environment: Development (local) â†’ Cloud (later)
Version Control: Git + GitHub
```

### External Services
```yaml
AI Provider: OpenAI API
File Storage: Local (dev) â†’ AWS S3 / Azure Blob (prod)
Google Sheets: Google Sheets API
Email: SendGrid / SMTP
```

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT TIER                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   React Frontend (TypeScript + Tailwind CSS)        â”‚   â”‚
â”‚  â”‚   - Landing, Auth, Dashboard, Analysis, Settings   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTPS/REST
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      APPLICATION TIER                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         FastAPI Backend (Python)                     â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Auth Service â”‚  â”‚ Data Service â”‚  â”‚ AI Serviceâ”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚   â”‚
â”‚  â”‚  â”‚ Query Engine â”‚  â”‚ File Handler â”‚                â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                â”‚
               â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DATABASE TIER      â”‚  â”‚   CACHE TIER         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  PostgreSQL    â”‚  â”‚  â”‚  â”‚     Redis      â”‚  â”‚
â”‚  â”‚  - Users       â”‚  â”‚  â”‚  â”‚  - Sessions    â”‚  â”‚
â”‚  â”‚  - DataSources â”‚  â”‚  â”‚  â”‚  - Query Cache â”‚  â”‚
â”‚  â”‚  - Queries     â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FILE STORAGE                       â”‚
â”‚  - CSV Files                                 â”‚
â”‚  - Uploaded Documents                        â”‚
â”‚  - Processed Data                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        EXTERNAL SERVICES                     â”‚
â”‚  - OpenAI API (GPT-4)                       â”‚
â”‚  - Google Sheets API                        â”‚
â”‚  - Third-party APIs                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—„ï¸ Database Schema

### Entity Relationship Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     users       â”‚         â”‚  data_sources   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)         â”‚â”€â”€â”€â”€â”€â”€â”€â”€<â”‚ user_id (FK)    â”‚
â”‚ email           â”‚    1:N  â”‚ id (PK)         â”‚
â”‚ password_hash   â”‚         â”‚ name            â”‚
â”‚ full_name       â”‚         â”‚ type            â”‚
â”‚ created_at      â”‚         â”‚ status          â”‚
â”‚ updated_at      â”‚         â”‚ file_path       â”‚
â”‚ is_active       â”‚         â”‚ connection_info â”‚
â”‚ is_verified     â”‚         â”‚ row_count       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ file_size       â”‚
                            â”‚ created_at      â”‚
                            â”‚ updated_at      â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â”‚ 1:N
                                     â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚    queries      â”‚
                            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                            â”‚ id (PK)         â”‚
                            â”‚ user_id (FK)    â”‚
                            â”‚ data_source_id  â”‚
                            â”‚ query_text      â”‚
                            â”‚ query_type      â”‚
                            â”‚ result_data     â”‚
                            â”‚ execution_time  â”‚
                            â”‚ is_saved        â”‚
                            â”‚ created_at      â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â”‚ 1:N
                                     â–¼
                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚ visualizations  â”‚
                            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                            â”‚ id (PK)         â”‚
                            â”‚ query_id (FK)   â”‚
                            â”‚ chart_type      â”‚
                            â”‚ config_json     â”‚
                            â”‚ created_at      â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Table Definitions

#### **users**
```sql
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    full_name VARCHAR(255) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    is_active BOOLEAN DEFAULT TRUE,
    is_verified BOOLEAN DEFAULT FALSE,
    last_login TIMESTAMP
);

CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_created_at ON users(created_at);
```

#### **data_sources**
```sql
CREATE TABLE data_sources (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    name VARCHAR(255) NOT NULL,
    type VARCHAR(50) NOT NULL, -- 'csv', 'google_sheets', 'api', 'database'
    status VARCHAR(50) DEFAULT 'connected', -- 'connected', 'syncing', 'error', 'disconnected'
    file_path TEXT, -- For CSV files
    connection_info JSONB, -- For API/Database connections
    row_count INTEGER,
    file_size BIGINT, -- In bytes
    columns_info JSONB, -- Column names and types
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_synced_at TIMESTAMP
);

CREATE INDEX idx_data_sources_user_id ON data_sources(user_id);
CREATE INDEX idx_data_sources_type ON data_sources(type);
CREATE INDEX idx_data_sources_status ON data_sources(status);
```

#### **queries**
```sql
CREATE TABLE queries (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    data_source_id UUID REFERENCES data_sources(id) ON DELETE SET NULL,
    query_text TEXT NOT NULL,
    query_type VARCHAR(50), -- 'natural_language', 'sql', 'aggregation'
    result_data JSONB, -- Store query results
    execution_time_ms INTEGER,
    is_saved BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_queries_user_id ON queries(user_id);
CREATE INDEX idx_queries_data_source_id ON queries(data_source_id);
CREATE INDEX idx_queries_created_at ON queries(created_at DESC);
CREATE INDEX idx_queries_is_saved ON queries(is_saved) WHERE is_saved = TRUE;
```

#### **visualizations**
```sql
CREATE TABLE visualizations (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    query_id UUID NOT NULL REFERENCES queries(id) ON DELETE CASCADE,
    chart_type VARCHAR(50) NOT NULL, -- 'line', 'bar', 'pie', 'table', 'scatter'
    config_json JSONB NOT NULL, -- Chart configuration
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_visualizations_query_id ON visualizations(query_id);
```

#### **api_keys** (for user API access)
```sql
CREATE TABLE api_keys (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    key_name VARCHAR(255) NOT NULL,
    key_hash VARCHAR(255) NOT NULL UNIQUE,
    key_prefix VARCHAR(20) NOT NULL, -- First 8 chars for display
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_used_at TIMESTAMP
);

CREATE INDEX idx_api_keys_user_id ON api_keys(user_id);
CREATE INDEX idx_api_keys_key_hash ON api_keys(key_hash);
```

#### **sessions** (optional - can use Redis instead)
```sql
CREATE TABLE sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    token_hash VARCHAR(255) NOT NULL UNIQUE,
    expires_at TIMESTAMP NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ip_address VARCHAR(45),
    user_agent TEXT
);

CREATE INDEX idx_sessions_user_id ON sessions(user_id);
CREATE INDEX idx_sessions_token_hash ON sessions(token_hash);
CREATE INDEX idx_sessions_expires_at ON sessions(expires_at);
```

---

## ğŸ”Œ API Design

### Base URL
```
Development: http://localhost:8000/api/v1
Production:  https://api.insightiq.com/api/v1
```

### Authentication
All protected endpoints require JWT token in header:
```
Authorization: Bearer <jwt_token>
```

### API Endpoints

#### **Authentication**

```http
POST   /auth/register
POST   /auth/login
POST   /auth/logout
POST   /auth/refresh
GET    /auth/me
POST   /auth/verify-email
POST   /auth/forgot-password
POST   /auth/reset-password
```

**Example: Register**
```json
POST /api/v1/auth/register
{
  "email": "user@example.com",
  "password": "SecurePass123!",
  "full_name": "John Doe"
}

Response 201:
{
  "id": "uuid",
  "email": "user@example.com",
  "full_name": "John Doe",
  "created_at": "2024-11-30T12:00:00Z"
}
```

**Example: Login**
```json
POST /api/v1/auth/login
{
  "email": "user@example.com",
  "password": "SecurePass123!"
}

Response 200:
{
  "access_token": "eyJhbGc...",
  "refresh_token": "eyJhbGc...",
  "token_type": "bearer",
  "expires_in": 3600,
  "user": {
    "id": "uuid",
    "email": "user@example.com",
    "full_name": "John Doe"
  }
}
```

#### **Data Sources**

```http
GET    /data-sources
POST   /data-sources/upload-csv
POST   /data-sources/connect-sheets
POST   /data-sources/connect-api
GET    /data-sources/{id}
PUT    /data-sources/{id}
DELETE /data-sources/{id}
POST   /data-sources/{id}/sync
GET    /data-sources/{id}/preview
```

**Example: Upload CSV**
```http
POST /api/v1/data-sources/upload-csv
Content-Type: multipart/form-data

file: <csv_file>
name: "Sales Data Q4"

Response 201:
{
  "id": "uuid",
  "name": "Sales Data Q4",
  "type": "csv",
  "status": "connected",
  "row_count": 15234,
  "file_size": 2411520,
  "columns_info": [
    {"name": "date", "type": "datetime"},
    {"name": "revenue", "type": "float"},
    {"name": "region", "type": "string"}
  ],
  "created_at": "2024-11-30T12:00:00Z"
}
```

#### **Queries & Analysis**

```http
POST   /queries/natural-language
POST   /queries/execute
GET    /queries
GET    /queries/{id}
DELETE /queries/{id}
POST   /queries/{id}/save
GET    /queries/saved
```

**Example: Natural Language Query**
```json
POST /api/v1/queries/natural-language
{
  "data_source_id": "uuid",
  "query_text": "What was the total revenue last quarter?"
}

Response 200:
{
  "id": "uuid",
  "query_text": "What was the total revenue last quarter?",
  "interpreted_query": "SELECT SUM(revenue) FROM data WHERE date >= '2024-07-01' AND date <= '2024-09-30'",
  "result_data": {
    "total_revenue": 1234567.89,
    "rows": [...]
  },
  "visualizations": [
    {
      "type": "kpi",
      "config": {...}
    }
  ],
  "execution_time_ms": 245,
  "created_at": "2024-11-30T12:00:00Z"
}
```

#### **Visualizations**

```http
GET    /visualizations/{query_id}
POST   /visualizations
PUT    /visualizations/{id}
DELETE /visualizations/{id}
```

#### **User Profile**

```http
GET    /users/me
PUT    /users/me
PUT    /users/me/password
POST   /users/me/avatar
```

#### **Statistics & Analytics**

```http
GET    /stats/dashboard
GET    /stats/usage
```

**Example: Dashboard Stats**
```json
GET /api/v1/stats/dashboard

Response 200:
{
  "data_sources_count": 12,
  "queries_count": 247,
  "queries_this_month": 56,
  "active_datasets": 8,
  "storage_used_bytes": 25165824,
  "storage_limit_bytes": 10737418240,
  "recent_activity": [...]
}
```

---

## ğŸ” Authentication & Security

### JWT Token Structure

```javascript
{
  "sub": "user_id",
  "email": "user@example.com",
  "exp": 1234567890,
  "iat": 1234567890,
  "type": "access" // or "refresh"
}
```

### Token Expiration
```
Access Token:  1 hour
Refresh Token: 30 days
```

### Password Requirements
```
- Minimum 8 characters
- At least 1 uppercase letter
- At least 1 lowercase letter
- At least 1 number
- At least 1 special character
```

### Security Measures
```yaml
Password Hashing: bcrypt (cost factor: 12)
JWT Algorithm: HS256
CORS: Configured for frontend domain only
Rate Limiting: 100 requests/minute per IP
SQL Injection: Parameterized queries via SQLAlchemy
XSS Protection: Content Security Policy headers
HTTPS: Required in production
```

### Environment Variables (Security)
```bash
# Never commit these to git!
JWT_SECRET_KEY=<random_256_bit_key>
JWT_REFRESH_SECRET_KEY=<random_256_bit_key>
DATABASE_URL=postgresql://user:pass@localhost:5432/insightiq
REDIS_URL=redis://localhost:6379/0
OPENAI_API_KEY=sk-...
GOOGLE_SHEETS_CREDENTIALS=<json_credentials>
```

---

## ğŸ”„ Data Flow

### 1. User Authentication Flow
```
User â†’ Frontend â†’ POST /auth/login
                     â†“
              Backend validates credentials
                     â†“
              Generate JWT tokens
                     â†“
              Store refresh token in Redis
                     â†“
              Return tokens to Frontend
                     â†“
              Frontend stores in memory/localStorage
                     â†“
              Include in Authorization header for requests
```

### 2. CSV Upload & Analysis Flow
```
User uploads CSV â†’ Frontend
                     â†“
              POST /data-sources/upload-csv
                     â†“
              Backend validates file
                     â†“
              Save file to storage
                     â†“
              Parse CSV with Pandas
                     â†“
              Extract metadata (columns, types, row count)
                     â†“
              Store metadata in PostgreSQL
                     â†“
              Return data source info to Frontend
                     â†“
              User sees data source in list
```

### 3. Natural Language Query Flow
```
User types query â†’ Frontend
                     â†“
              POST /queries/natural-language
                     â†“
              Backend receives query
                     â†“
              Send to OpenAI API (GPT-4)
                     â†“
              GPT-4 interprets query â†’ generates pandas code
                     â†“
              Execute code safely on data
                     â†“
              Generate visualization config
                     â†“
              Store query + results in PostgreSQL
                     â†“
              Cache results in Redis (5 min)
                     â†“
              Return results + viz to Frontend
                     â†“
              Frontend renders charts with Recharts
```

### 4. Google Sheets Connection Flow
```
User initiates connection â†’ Frontend
                              â†“
                    OAuth flow with Google
                              â†“
                    User grants permissions
                              â†“
                    Receive OAuth tokens
                              â†“
                    POST /data-sources/connect-sheets
                              â†“
                    Backend stores encrypted tokens
                              â†“
                    Fetch sheet data via Google Sheets API
                              â†“
                    Cache data in Redis
                              â†“
                    Store metadata in PostgreSQL
                              â†“
                    Return data source to Frontend
```

---

## ğŸ“ File Storage Strategy

### Development (Local)
```
/app/storage/
  â”œâ”€â”€ uploads/
  â”‚   â”œâ”€â”€ csv/
  â”‚   â”‚   â””â”€â”€ {user_id}/
  â”‚   â”‚       â””â”€â”€ {file_id}.csv
  â”‚   â””â”€â”€ temp/
  â””â”€â”€ processed/
      â””â”€â”€ {user_id}/
          â””â”€â”€ {data_source_id}.parquet
```

### Production (Cloud)
```
AWS S3 / Azure Blob Storage Structure:

insightiq-data/
  â”œâ”€â”€ users/{user_id}/
  â”‚   â”œâ”€â”€ uploads/
  â”‚   â”‚   â””â”€â”€ {file_id}.csv
  â”‚   â””â”€â”€ processed/
  â”‚       â””â”€â”€ {data_source_id}.parquet
  â””â”€â”€ temp/
      â””â”€â”€ {session_id}/
```

### File Handling
```python
# Maximum file size
MAX_FILE_SIZE = 100 * 1024 * 1024  # 100MB

# Allowed file types
ALLOWED_EXTENSIONS = {'.csv', '.xlsx', '.json'}

# File naming convention
file_name = f"{user_id}_{timestamp}_{original_name}"
```

---

## ğŸ”— External Integrations

### OpenAI API
```python
# Configuration
OPENAI_MODEL = "gpt-4-turbo"
MAX_TOKENS = 2000
TEMPERATURE = 0.2  # Low temperature for consistent analysis

# Usage
- Natural language query interpretation
- Data insight generation
- Anomaly detection
```

### Google Sheets API
```python
# Scopes required
SCOPES = [
    'https://www.googleapis.com/auth/spreadsheets.readonly',
    'https://www.googleapis.com/auth/drive.metadata.readonly'
]

# OAuth Flow
- User authorization
- Token storage (encrypted)
- Automatic refresh
```

### Future Integrations
```
- Stripe API (payments)
- Slack API (notifications)
- Zapier webhooks
- REST APIs (generic connector)
```

---

## ğŸš€ Deployment Architecture

### Docker Compose (Development)
```yaml
services:
  backend:
    build: ./backend
    ports: ["8000:8000"]
    depends_on: [postgres, redis]
    
  frontend:
    build: ./frontend
    ports: ["3000:3000"]
    depends_on: [backend]
    
  postgres:
    image: postgres:15
    ports: ["5432:5432"]
    volumes: [postgres_data:/var/lib/postgresql/data]
    
  redis:
    image: redis:7-alpine
    ports: ["6379:6379"]
    
  pgadmin:
    image: dpage/pgadmin4
    ports: ["5050:80"]
```

### Production (Future)
```
Load Balancer (Nginx)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (CDN)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Gateway     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (x3)    â”‚ â† Auto-scaling
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL      â”‚ â† Managed Database
â”‚  (RDS/Azure DB)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Redis           â”‚ â† Managed Cache
â”‚  (ElastiCache)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Performance Considerations

### Database Optimization
```sql
-- Indexing strategy
- Primary keys (UUID)
- Foreign keys
- Frequently queried columns (email, created_at, user_id)
- Composite indexes for common queries

-- Query optimization
- Use EXPLAIN ANALYZE
- Avoid N+1 queries
- Pagination for large result sets
- Connection pooling (min: 10, max: 20)
```

### Caching Strategy
```
Redis Cache Layers:
1. Query Results (TTL: 5 minutes)
2. User Sessions (TTL: 30 days)
3. Data Source Previews (TTL: 1 hour)
4. API Rate Limiting

Cache Keys Format:
- query:{data_source_id}:{query_hash}
- session:{token_hash}
- preview:{data_source_id}
```

### API Rate Limiting
```python
# Rate limits per endpoint
RATE_LIMITS = {
    "auth": "5/minute",      # Login attempts
    "queries": "30/minute",  # Query executions
    "uploads": "10/hour",    # File uploads
    "default": "100/minute"  # General API
}
```

---

## ğŸ§ª Testing Strategy

```yaml
Backend:
  - Unit Tests: pytest
  - Integration Tests: pytest + TestClient
  - Coverage Target: 80%+

Frontend:
  - Unit Tests: Vitest
  - Component Tests: React Testing Library
  - E2E Tests: Playwright (optional)

Database:
  - Migrations: Alembic
  - Fixtures: Factory pattern
  - Rollback tests
```

---

## ğŸ“ˆ Monitoring & Logging

```python
# Logging Levels
DEBUG:   Development detailed logs
INFO:    General application flow
WARNING: Unexpected behavior
ERROR:   Application errors
CRITICAL: System failures

# Metrics to Track
- API response times
- Database query times
- Query execution times
- Error rates
- User activity
- Resource usage (CPU, memory, disk)
```

---

## ğŸ”„ Version Control & Branching

```
main           - Production-ready code
develop        - Development branch
feature/*      - New features
bugfix/*       - Bug fixes
hotfix/*       - Urgent production fixes
```

---

## âœ… Next Steps

1. âœ… Set up project structure
2. âœ… Configure Docker Compose
3. âœ… Initialize database with migrations
4. âœ… Implement authentication system
5. âœ… Build API endpoints
6. âœ… Integrate OpenAI for NL queries
7. âœ… Develop frontend components
8. âœ… Connect frontend to backend
9. âœ… Testing & optimization
10. âœ… Deployment preparation

---

**End of System Design Document**